{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f9f3822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hsa-let-7a-1  hsa-let-7a-2  hsa-let-7a-3    hsa-let-7b   hsa-let-7c  \\\n",
      "0  14316.183948  14351.995128  14412.983601  12203.480690  6594.417741   \n",
      "1  18042.893723  17822.176422  18024.997726   8962.166370  3304.048522   \n",
      "2  23542.996389  23403.850012  23393.390262  10325.675423  6358.260398   \n",
      "3  35319.514700  35344.502424  35235.536971   7294.517488  5175.621787   \n",
      "4  10786.292006  10704.600259  10960.408721   4716.654860  3542.559611   \n",
      "\n",
      "    hsa-let-7d   hsa-let-7e  hsa-let-7f-1  hsa-let-7f-2   hsa-let-7g  ...  \\\n",
      "0   798.167093  2007.302666   7279.990730   7366.938399   861.970419  ...   \n",
      "1  3772.327121  4741.693647   5520.915201   5780.407164   472.006932  ...   \n",
      "2  1129.019119  4283.426272  16578.070468  16638.927197  1227.594343  ...   \n",
      "3   950.956848  6652.902332  35001.632900  35642.299155  2407.045273  ...   \n",
      "4  3325.510007  2781.097126   8194.218848   8312.284292  2685.094417  ...   \n",
      "\n",
      "   hsa-mir-942  hsa-mir-943  hsa-mir-944  hsa-mir-95  hsa-mir-9500  \\\n",
      "0     2.032949     0.000000     0.312761   14.699786             0   \n",
      "1     9.693665     0.000000     0.000000   20.878664             0   \n",
      "2     4.120508     0.316962     1.267849    8.557978             0   \n",
      "3     1.265201     0.158150     0.474450   16.605766             0   \n",
      "4     2.385160     0.000000     0.000000   39.355148             0   \n",
      "\n",
      "   hsa-mir-96  hsa-mir-98  hsa-mir-99a    hsa-mir-99b  Label  \n",
      "0   12.354075   82.881771  1937.869635   36571.972419      3  \n",
      "1    4.473999   15.658998  2320.514331  113675.375555      1  \n",
      "2   15.214182   97.307375  1719.836536   36302.307072      1  \n",
      "3   11.544961   78.126174  1490.407007   28383.207301      1  \n",
      "4    7.155481  103.158191   680.963319  125770.108692      4  \n",
      "\n",
      "[5 rows x 1882 columns]\n",
      "hsa-let-7a-1    0\n",
      "hsa-let-7a-2    0\n",
      "hsa-let-7a-3    0\n",
      "hsa-let-7b      0\n",
      "hsa-let-7c      0\n",
      "               ..\n",
      "hsa-mir-96      0\n",
      "hsa-mir-98      0\n",
      "hsa-mir-99a     0\n",
      "hsa-mir-99b     0\n",
      "Label           0\n",
      "Length: 1882, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Thyloid.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00873bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c074b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced data shape: (574, 400)\n",
      "Number of components retained: 400\n",
      "Reduced data shape (sklearn): (574, 400)\n",
      "Explained variance ratio (sklearn): [0.04777769 0.03725629 0.03427611 0.0265207  0.02182789 0.01832401\n",
      " 0.01549001 0.01450249 0.01206209 0.01151309 0.01066848 0.00945816\n",
      " 0.00923541 0.00881043 0.00846386 0.00774428 0.00758392 0.00717494\n",
      " 0.00702501 0.0065385  0.00632394 0.00597568 0.00595614 0.00566321\n",
      " 0.00527935 0.00509829 0.00503669 0.00479993 0.0047587  0.00471187\n",
      " 0.00456325 0.004299   0.00428154 0.00423483 0.00418563 0.00408096\n",
      " 0.00406631 0.0040213  0.00392481 0.0038951  0.0037937  0.00374534\n",
      " 0.00368772 0.00366683 0.00358775 0.0035479  0.00349782 0.00346277\n",
      " 0.00340288 0.00338083 0.00333573 0.00330953 0.00327049 0.00323506\n",
      " 0.00321189 0.00318098 0.00316745 0.00313947 0.00308969 0.00306535\n",
      " 0.00303164 0.00301099 0.00297727 0.00294546 0.0029335  0.0029102\n",
      " 0.00286837 0.00286819 0.00284626 0.00283578 0.00280194 0.0027964\n",
      " 0.00277202 0.0027444  0.00272778 0.00271292 0.00267641 0.00266146\n",
      " 0.00263923 0.00261962 0.00259881 0.00258434 0.00257766 0.00255951\n",
      " 0.00254392 0.00253696 0.00252515 0.00247347 0.00245473 0.00244395\n",
      " 0.00243679 0.00242991 0.00241115 0.00240503 0.00237781 0.00235706\n",
      " 0.00234857 0.00234117 0.0023299  0.00231499 0.00230242 0.00228637\n",
      " 0.00227198 0.00226346 0.00224651 0.00222959 0.00221837 0.00221412\n",
      " 0.00219926 0.00218401 0.0021708  0.00216487 0.00215345 0.00213946\n",
      " 0.00213408 0.00211944 0.00211402 0.00210151 0.00209636 0.00207456\n",
      " 0.00206708 0.0020349  0.00203014 0.0020207  0.00200662 0.0019947\n",
      " 0.00198407 0.00198011 0.00196183 0.00195876 0.00194662 0.00193701\n",
      " 0.00192479 0.00190793 0.00190708 0.00190525 0.0018893  0.00187528\n",
      " 0.0018651  0.00186202 0.00184988 0.00184444 0.00183125 0.00182439\n",
      " 0.00181653 0.00181118 0.00178938 0.00178037 0.00177713 0.00177211\n",
      " 0.00176315 0.00175763 0.00175272 0.0017426  0.00173628 0.0017174\n",
      " 0.00170781 0.00170016 0.00169293 0.00168259 0.00167998 0.00167149\n",
      " 0.00166259 0.00165254 0.00164555 0.00163741 0.00162961 0.00162566\n",
      " 0.00161651 0.00161018 0.00160527 0.00159423 0.00158401 0.00157876\n",
      " 0.00157599 0.00156481 0.00155234 0.00153981 0.00153331 0.00153229\n",
      " 0.00152625 0.00151655 0.00150819 0.00150622 0.00150021 0.00149417\n",
      " 0.00149154 0.00148014 0.00147765 0.00147066 0.00145821 0.00145722\n",
      " 0.00145255 0.0014418  0.00142902 0.00141971 0.00141328 0.00140961\n",
      " 0.00140275 0.0013983  0.00139097 0.00138407 0.00138041 0.00137291\n",
      " 0.00136881 0.00135541 0.00135253 0.00134578 0.00134101 0.00133503\n",
      " 0.00133076 0.00132888 0.00132328 0.00131123 0.0013051  0.00129873\n",
      " 0.00129273 0.00129172 0.00128575 0.00128109 0.00127765 0.00127037\n",
      " 0.00126346 0.00126182 0.0012545  0.00124861 0.00124484 0.0012413\n",
      " 0.0012333  0.00122785 0.0012147  0.00121199 0.00120698 0.00120356\n",
      " 0.00119515 0.00118996 0.00118814 0.00118032 0.00117771 0.00117277\n",
      " 0.00117152 0.0011689  0.00115286 0.00115054 0.00114621 0.00113518\n",
      " 0.00112798 0.00112003 0.00111493 0.00111299 0.00110986 0.00110623\n",
      " 0.00110393 0.00109789 0.0010907  0.00108384 0.00107837 0.0010748\n",
      " 0.00106845 0.00106452 0.00106148 0.00105669 0.00105487 0.00105042\n",
      " 0.0010445  0.00103585 0.00103313 0.00102975 0.00102169 0.00101673\n",
      " 0.00100926 0.00100637 0.00100545 0.00099711 0.00099386 0.00098805\n",
      " 0.000986   0.00097735 0.00097448 0.0009686  0.00096333 0.00095953\n",
      " 0.00095466 0.00094832 0.00094336 0.00093906 0.00093072 0.00092949\n",
      " 0.00092742 0.00092031 0.00091649 0.00091252 0.00090845 0.00090049\n",
      " 0.00089668 0.00089426 0.00089029 0.00088839 0.00087981 0.00087464\n",
      " 0.00087053 0.0008661  0.0008638  0.00085897 0.00085647 0.00084995\n",
      " 0.00084931 0.0008438  0.00083894 0.00083129 0.00082667 0.00082538\n",
      " 0.0008197  0.00081727 0.0008168  0.00080895 0.00080619 0.0008009\n",
      " 0.00079642 0.00079173 0.00078997 0.00078744 0.0007815  0.00078043\n",
      " 0.00077665 0.00077327 0.00076713 0.0007652  0.00075532 0.00075377\n",
      " 0.00075032 0.00074805 0.00074419 0.00074076 0.00073094 0.00072353\n",
      " 0.00072313 0.00071899 0.00071401 0.00071112 0.0007055  0.00070159\n",
      " 0.00069879 0.00069193 0.00068929 0.00068748 0.00068531 0.00068295\n",
      " 0.00068082 0.00067793 0.00067554 0.00067153 0.00066571 0.00066088\n",
      " 0.00066023 0.00065699 0.00065392 0.00064604 0.00064382 0.0006398\n",
      " 0.00063658 0.0006348  0.0006314  0.00062718 0.00062326 0.00061768\n",
      " 0.00061417 0.00060963 0.00060207 0.00060141 0.00060028 0.00059813\n",
      " 0.00059327 0.00058962 0.0005873  0.00058485 0.00058017 0.0005763\n",
      " 0.00057572 0.00057248 0.00056974 0.00056381 0.00055872 0.00055731\n",
      " 0.00055277 0.00055011 0.00054764 0.00054452 0.0005403  0.00053638\n",
      " 0.00053438 0.00053295 0.00052855 0.00052391 0.00052241 0.00051954\n",
      " 0.0005178  0.00051585 0.00051381 0.00050574]\n",
      "Number of components retained (sklearn): 400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def load_and_impute_data(file_path):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate labels from features\n",
    "    labels = data['Label']\n",
    "    features = data.drop(columns=['Label'])\n",
    "    \n",
    "    # Handle missing values by imputing with the mean\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features_imputed = pd.DataFrame(imputer.fit_transform(features), columns=features.columns)\n",
    "    \n",
    "    # Debug: Check for NaNs after imputation\n",
    "    if features_imputed.isnull().sum().sum() > 0:\n",
    "        raise ValueError(\"NaN values found in imputed data\")\n",
    "    \n",
    "    # Combine imputed features with labels\n",
    "    data_imputed = pd.concat([features_imputed, labels], axis=1)\n",
    "    \n",
    "    return data_imputed\n",
    "\n",
    "def normalize_data(features):\n",
    "    # Remove columns with zero variance\n",
    "    non_zero_variance_features = features.loc[:, features.var() != 0]\n",
    "    \n",
    "    # Normalize the data by subtracting the mean and dividing by the standard deviation\n",
    "    features_normalized = (non_zero_variance_features - non_zero_variance_features.mean()) / non_zero_variance_features.std()\n",
    "    \n",
    "    # Debug: Check for NaNs after normalization and identify columns with NaNs\n",
    "    nan_columns = features_normalized.columns[features_normalized.isnull().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values found in normalized data for columns: {nan_columns}\")\n",
    "    \n",
    "    return features_normalized\n",
    "\n",
    "def compute_covariance_matrix(data):\n",
    "    # Compute the covariance matrix\n",
    "    covariance_matrix = np.cov(data.T)\n",
    "    return covariance_matrix\n",
    "\n",
    "def compute_eigenvalues_eigenvectors(covariance_matrix):\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def sort_eigenvalues_eigenvectors(eigenvalues, eigenvectors):\n",
    "    # Sort the eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def project_data(data, eigenvectors, num_components):\n",
    "    # Project the data onto the selected eigenvectors\n",
    "    return np.dot(data, eigenvectors[:, :num_components])\n",
    "\n",
    "def pca_from_scratch(file_path, variance_threshold=0.95):\n",
    "    # Load and impute the data\n",
    "    data = load_and_impute_data(file_path)\n",
    "    labels = data['Label']  # Correctly using 'Label' as the column name for the labels\n",
    "    features = data.drop(columns=['Label'])\n",
    "    normalized_data = normalize_data(features)\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    covariance_matrix = compute_covariance_matrix(normalized_data)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = compute_eigenvalues_eigenvectors(covariance_matrix)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = sort_eigenvalues_eigenvectors(eigenvalues, eigenvectors)\n",
    "\n",
    "    # Determine the number of principal components to retain the desired variance\n",
    "    total_variance = sum(eigenvalues)\n",
    "    variance_explained = 0\n",
    "    num_components = 0\n",
    "    for eigenvalue in eigenvalues:\n",
    "        variance_explained += eigenvalue\n",
    "        num_components += 1\n",
    "        if variance_explained / total_variance >= variance_threshold:\n",
    "            break\n",
    "\n",
    "    # Project the data onto the principal components\n",
    "    reduced_data = project_data(normalized_data, eigenvectors, num_components)\n",
    "\n",
    "    return reduced_data, num_components\n",
    "\n",
    "# Usage\n",
    "file_path = 'Thyloid.csv'\n",
    "reduced_data, num_components = pca_from_scratch(file_path)\n",
    "print(f'Reduced data shape: {reduced_data.shape}')\n",
    "print(f'Number of components retained: {num_components}')\n",
    "\n",
    "# PCA using scikit-learn\n",
    "data = load_and_impute_data(file_path)\n",
    "labels = data['Label']\n",
    "features = data.drop(columns=['Label'])\n",
    "\n",
    "# Normalize the data\n",
    "normalized_data = normalize_data(features)\n",
    "\n",
    "# Verify no NaNs in the normalized data (Already handled inside normalize_data function)\n",
    "\n",
    "# Apply PCA using scikit-learn\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "reduced_data_sklearn = pca.fit_transform(normalized_data)\n",
    "\n",
    "print(f'Reduced data shape (sklearn): {reduced_data_sklearn.shape}')\n",
    "print(f'Explained variance ratio (sklearn): {pca.explained_variance_ratio_}')\n",
    "print(f'Number of components retained (sklearn): {pca.n_components_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65b56c2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     28\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 29\u001b[0m X_kpca_rbf \u001b[38;5;241m=\u001b[39m kpca_rbf(normalized_data, gamma, n_components)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReduced data shape (KPCA with RBF): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_kpca_rbf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m, in \u001b[0;36mkpca_rbf\u001b[0;34m(X, gamma, n_components)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkpca_rbf\u001b[39m(X, gamma, n_components):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute the RBF kernel matrix\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     K \u001b[38;5;241m=\u001b[39m rbf_kernel(X, gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Center the kernel matrix\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     N \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1310\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[0;34m(X, Y, gamma)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrbf_kernel\u001b[39m(X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the rbf (gaussian) kernel between X and Y.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \n\u001b[1;32m   1288\u001b[0m \u001b[38;5;124;03m        K(x, y) = exp(-gamma ||x-y||^2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03m        The RBF kernel.\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1310\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:146\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    147\u001b[0m         X,\n\u001b[1;32m    148\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m    149\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    150\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    151\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    152\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def kpca_rbf(X, gamma, n_components):\n",
    "    # Compute the RBF kernel matrix\n",
    "    K = rbf_kernel(X, gamma=gamma)\n",
    "    \n",
    "    # Center the kernel matrix\n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N, N)) / N\n",
    "    K_centered = K - one_n @ K - K @ one_n + one_n @ K @ one_n\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = eigh(K_centered)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    \n",
    "    # Select the top n_components eigenvectors (principal components)\n",
    "    X_kpca = np.dot(K_centered, eigenvectors[:, :n_components])\n",
    "    \n",
    "    return X_kpca\n",
    "\n",
    "# Usage example\n",
    "gamma = 0.1\n",
    "n_components = 10\n",
    "X_kpca_rbf = kpca_rbf(normalized_data, gamma, n_components)\n",
    "print(f'Reduced data shape (KPCA with RBF): {X_kpca_rbf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c05edeed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_kernel(X, \u001b[38;5;28;01mlambda\u001b[39;00m X: rbf_kernel(X, gamma\u001b[38;5;241m=\u001b[39mgamma), \u001b[38;5;28;01mlambda\u001b[39;00m X: polynomial_kernel(X, degree, coef0), alpha)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Perform KPCA with the combined kernel\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m alphas_combined, lambdas_combined \u001b[38;5;241m=\u001b[39m kpca(normalized_data, combined_kernel_func, num_components)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKPCA (Combined Kernels) - reduced data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphas_combined\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m, in \u001b[0;36mkpca\u001b[0;34m(X, kernel_func, n_components)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkpca\u001b[39m(X, kernel_func, n_components):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Compute the kernel matrix\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel_func(X)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Center the kernel matrix\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     N \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[36], line 42\u001b[0m, in \u001b[0;36mcombined_kernel_func\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombined_kernel_func\u001b[39m(X):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_kernel(X, \u001b[38;5;28;01mlambda\u001b[39;00m X: rbf_kernel(X, gamma\u001b[38;5;241m=\u001b[39mgamma), \u001b[38;5;28;01mlambda\u001b[39;00m X: polynomial_kernel(X, degree, coef0), alpha)\n",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m, in \u001b[0;36mcombined_kernel\u001b[0;34m(X, kernel1, kernel2, alpha)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombined_kernel\u001b[39m(X, kernel1, kernel2, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m alpha \u001b[38;5;241m*\u001b[39m kernel1(X) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m kernel2(X)\n",
      "Cell \u001b[0;32mIn[36], line 42\u001b[0m, in \u001b[0;36mcombined_kernel_func.<locals>.<lambda>\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombined_kernel_func\u001b[39m(X):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_kernel(X, \u001b[38;5;28;01mlambda\u001b[39;00m X: rbf_kernel(X, gamma\u001b[38;5;241m=\u001b[39mgamma), \u001b[38;5;28;01mlambda\u001b[39;00m X: polynomial_kernel(X, degree, coef0), alpha)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1310\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[0;34m(X, Y, gamma)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrbf_kernel\u001b[39m(X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the rbf (gaussian) kernel between X and Y.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \n\u001b[1;32m   1288\u001b[0m \u001b[38;5;124;03m        K(x, y) = exp(-gamma ||x-y||^2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03m        The RBF kernel.\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1310\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:146\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    147\u001b[0m         X,\n\u001b[1;32m    148\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m    149\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    150\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    151\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    152\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def polynomial_kernel(X, degree, coef0):\n",
    "    return (X @ X.T + coef0) ** degree\n",
    "\n",
    "def combined_kernel(X, kernel1, kernel2, alpha=0.5):\n",
    "    return alpha * kernel1(X) + (1 - alpha) * kernel2(X)\n",
    "\n",
    "def kpca(X, kernel_func, n_components):\n",
    "    # Compute the kernel matrix\n",
    "    K = kernel_func(X)\n",
    "    \n",
    "    # Center the kernel matrix\n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N, N)) / N\n",
    "    K_centered = K - one_n @ K - K @ one_n + one_n @ K @ one_n\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = eigh(K_centered)\n",
    "    eigenvalues, eigenvectors = eigenvalues[::-1], eigenvectors[:, ::-1]\n",
    "    \n",
    "    # Select the top n_components eigenvectors (alphas) and eigenvalues (lambdas)\n",
    "    alphas = eigenvectors[:, :n_components]\n",
    "    lambdas = eigenvalues[:n_components]\n",
    "    \n",
    "    # Normalize the eigenvectors (alphas)\n",
    "    for i in range(n_components):\n",
    "        alphas[:, i] = alphas[:, i] / np.sqrt(lambdas[i])\n",
    "    \n",
    "    return alphas, lambdas\n",
    "\n",
    "# Usage for Combined Kernels\n",
    "gamma = 0.1\n",
    "degree = 3\n",
    "coef0 = 1\n",
    "alpha = 0.5\n",
    "num_components = 10 \n",
    "\n",
    "# Define the combined kernel function\n",
    "def combined_kernel_func(X):\n",
    "    return combined_kernel(X, lambda X: rbf_kernel(X, gamma=gamma), lambda X: polynomial_kernel(X, degree, coef0), alpha)\n",
    "\n",
    "# Perform KPCA with the combined kernel\n",
    "alphas_combined, lambdas_combined = kpca(normalized_data, combined_kernel_func, num_components)\n",
    "\n",
    "print(f'KPCA (Combined Kernels) - reduced data shape: {alphas_combined.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2519f198",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X \u001b[38;5;241m@\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Usage for Linear Kernel\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m alphas_linear, lambdas_linear \u001b[38;5;241m=\u001b[39m kpca(normalized_data, linear_kernel, num_components)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKPCA (Linear Kernel) - reduced data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphas_linear\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 20\u001b[0m, in \u001b[0;36mkpca\u001b[0;34m(X, kernel_func, n_components)\u001b[0m\n\u001b[1;32m     17\u001b[0m K_centered \u001b[38;5;241m=\u001b[39m K \u001b[38;5;241m-\u001b[39m one_n \u001b[38;5;241m@\u001b[39m K \u001b[38;5;241m-\u001b[39m K \u001b[38;5;241m@\u001b[39m one_n \u001b[38;5;241m+\u001b[39m one_n \u001b[38;5;241m@\u001b[39m K \u001b[38;5;241m@\u001b[39m one_n\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Compute eigenvalues and eigenvectors\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m eigh(K_centered)\n\u001b[1;32m     21\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m eigenvalues[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], eigenvectors[:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Select the top n_components eigenvectors (alphas) and eigenvalues (lambdas)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/linalg/_decomp.py:460\u001b[0m, in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m drv_str:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is unknown. Possible values are \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    458\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(driver, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(drv_str[\u001b[38;5;241m1\u001b[39m:])))\n\u001b[0;32m--> 460\u001b[0m a1 \u001b[38;5;241m=\u001b[39m _asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected square \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/_lib/_util.py:240\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    239\u001b[0m toarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray_chkfinite \u001b[38;5;28;01mif\u001b[39;00m check_finite \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray\n\u001b[0;32m--> 240\u001b[0m a \u001b[38;5;241m=\u001b[39m toarray(a)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "def linear_kernel(X):\n",
    "    return X @ X.T\n",
    "\n",
    "# Usage for Linear Kernel\n",
    "alphas_linear, lambdas_linear = kpca(normalized_data, linear_kernel, num_components)\n",
    "\n",
    "print(f'KPCA (Linear Kernel) - reduced data shape: {alphas_linear.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7373fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f261be28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features with highest covariance: Index(['hsa-mir-422a', 'hsa-mir-4464', 'hsa-mir-3186', 'hsa-mir-299',\n",
      "       'hsa-mir-4321', 'hsa-mir-301a', 'hsa-mir-494', 'hsa-mir-4771-2',\n",
      "       'hsa-mir-1245a', 'hsa-mir-3606'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def top_features_by_covariance(cov_matrix, top_n=10):\n",
    "    covariances = np.diag(cov_matrix)\n",
    "    top_indices = np.argsort(covariances)[-top_n:]\n",
    "    return top_indices\n",
    "\n",
    "# Calculate covariance matrix\n",
    "cov_matrix = compute_covariance_matrix(normalized_data)\n",
    "\n",
    "# Identify top 10 features with highest covariance\n",
    "top_features_indices = top_features_by_covariance(cov_matrix)\n",
    "top_features = features.columns[top_features_indices]\n",
    "\n",
    "print(f'Top 10 features with highest covariance: {top_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4537d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the distance between two points\n",
    "def dis(x1, x2):\n",
    "    return np.linalg.norm(x1 - x2)\n",
    "\n",
    "# Function to perform classification\n",
    "def myclassifier(train_data, train_labels, test_data):\n",
    "    pred = []\n",
    "\n",
    "    for testpoint in test_data:\n",
    "        pred_dis = []\n",
    "        for trainpoint in train_data:\n",
    "            pred_dis.append(dis(testpoint, trainpoint))\n",
    "\n",
    "        pred.append(train_labels[np.argmin(pred_dis)])\n",
    "\n",
    "    return np.array(pred)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(true_labels, predicted_labels):\n",
    "    # Ensure that the true labels and predicted labels have the same length\n",
    "    if len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"Length of true_labels and predicted_labels must be the same.\")\n",
    "\n",
    "    # Count the number of correct predictions\n",
    "    correct_predictions = sum(1 for true, predicted in zip(true_labels, predicted_labels) if true == predicted)\n",
    "\n",
    "    # Calculate accuracy as the ratio of correct predictions to total predictions\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5edcb914",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "148",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 148",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m test_data_kpca_rbf, _ \u001b[38;5;241m=\u001b[39m kpca(test_data, \u001b[38;5;28;01mlambda\u001b[39;00m X: rbf_kernel(X, gamma\u001b[38;5;241m=\u001b[39mgamma), num_components)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform classification using the minimum distance classifier\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m predictions_pca \u001b[38;5;241m=\u001b[39m myclassifier(train_data_pca, train_labels, test_data_pca)\n\u001b[1;32m     25\u001b[0m predictions_kpca_rbf \u001b[38;5;241m=\u001b[39m myclassifier(train_data_kpca_rbf, train_labels, test_data_kpca_rbf)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m, in \u001b[0;36mmyclassifier\u001b[0;34m(train_data, train_labels, test_data)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trainpoint \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m     14\u001b[0m         pred_dis\u001b[38;5;241m.\u001b[39mappend(dis(testpoint, trainpoint))\n\u001b[0;32m---> 16\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(train_labels[np\u001b[38;5;241m.\u001b[39margmin(pred_dis)])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 148"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(normalized_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply PCA on the training data using scikit-learn\n",
    "pca = PCA(n_components=0.95)\n",
    "train_data_pca = pca.fit_transform(train_data)\n",
    "test_data_pca = pca.transform(test_data)\n",
    "\n",
    "# Apply KPCA on the training data\n",
    "gamma = 0.1\n",
    "degree = 3\n",
    "coef0 = 1\n",
    "alpha = 0.5\n",
    "num_components = 10  # Adjust this number based on your needs\n",
    "\n",
    "# KPCA with RBF Kernel\n",
    "train_data_kpca_rbf, _ = kpca(train_data, lambda X: rbf_kernel(X, gamma=gamma), num_components)\n",
    "test_data_kpca_rbf, _ = kpca(test_data, lambda X: rbf_kernel(X, gamma=gamma), num_components)\n",
    "\n",
    "# Perform classification using the minimum distance classifier\n",
    "predictions_pca = myclassifier(train_data_pca, train_labels, test_data_pca)\n",
    "predictions_kpca_rbf = myclassifier(train_data_kpca_rbf, train_labels, test_data_kpca_rbf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_pca = calculate_accuracy(test_labels, predictions_pca)\n",
    "accuracy_kpca_rbf = calculate_accuracy(test_labels, predictions_kpca_rbf)\n",
    "\n",
    "print(f'PCA Accuracy: {accuracy_pca}')\n",
    "print(f'KPCA (RBF Kernel) Accuracy: {accuracy_kpca_rbf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac0a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
